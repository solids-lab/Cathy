#!/usr/bin/env python3
"""
åˆ†å¸ƒå¼æ¸¯å£å®¢æˆ·ç«¯
æ¯ä¸ªæ¸¯å£åœ¨ç‹¬ç«‹çš„ç»ˆç«¯/æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œé€šè¿‡ç½‘ç»œè¿›è¡Œè”é‚¦å­¦ä¹ 
"""

import sys
import os
import argparse
import time
import json
import socket
import threading
from pathlib import Path
from datetime import datetime
import logging

# è®¾ç½®é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ç½‘ç»œé€šä¿¡
import requests
import torch
import numpy as np

# CityFlowå¯¼å…¥
try:
    import cityflow
    CITYFLOW_AVAILABLE = True
except ImportError:
    CITYFLOW_AVAILABLE = False

# è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥
from src.models.maritime_gat_ppo import MaritimeGATPPOAgent
from src.models.fairness_reward import AlphaFairRewardCalculator

class DistributedPortClient:
    """åˆ†å¸ƒå¼æ¸¯å£å®¢æˆ·ç«¯ - åœ¨ç‹¬ç«‹ç»ˆç«¯/æœåŠ¡å™¨ä¸Šè¿è¡Œ"""
    
    def __init__(self, port_id: int, port_name: str, server_host: str = "localhost", 
                 server_port: int = 8888, topology_size: str = "3x3"):
        self.port_id = port_id
        self.port_name = port_name
        self.server_host = server_host
        self.server_port = server_port
        self.topology_size = topology_size
        
        # å®¢æˆ·ç«¯æ ‡è¯†
        self.client_id = f"port_{port_id}_{port_name}"
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logging()
        
        # CityFlowç¯å¢ƒ
        self.cityflow_env = None
        self.current_step = 0
        self.max_steps = 1000
        
        # GAT-PPOæ™ºèƒ½ä½“
        self.state_dim = 4
        self.action_dim = 4
        self.node_num = 9 if topology_size == "3x3" else 16
        
        self.gat_ppo_agent = MaritimeGATPPOAgent(
            node_num=self.node_num,
            node_dim=self.state_dim,
            action_dim=self.action_dim
        )
        
        # å…¬å¹³æ€§å¥–åŠ±è®¡ç®—å™¨
        self.fairness_calculator = AlphaFairRewardCalculator(alpha=0.5)
        
        # è®­ç»ƒå†å²
        self.training_history = []
        self.local_model_version = 0
        
        self.logger.info(f"ğŸ­ åˆ†å¸ƒå¼æ¸¯å£å®¢æˆ·ç«¯åˆå§‹åŒ–: {port_name} (ID: {port_id})")
        self.logger.info(f"ğŸ“¡ æœåŠ¡å™¨åœ°å€: {server_host}:{server_port}")
        
        # åˆå§‹åŒ–CityFlowç¯å¢ƒ
        self._initialize_cityflow()
        
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(f"Port_{self.port_name}")
        logger.setLevel(logging.INFO)
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        log_dir = project_root / "src" / "federated" / "logs"
        log_dir.mkdir(exist_ok=True)
        
        handler = logging.FileHandler(log_dir / f"port_{self.port_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        
        logger.addHandler(handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def _initialize_cityflow(self):
        """åˆå§‹åŒ–CityFlowç¯å¢ƒ"""
        try:
            if CITYFLOW_AVAILABLE:
                # åˆ›å»ºæ¸¯å£ç‰¹å®šçš„é…ç½®
                config_file = self._create_port_config()
                self.cityflow_env = cityflow.Engine(config_file, thread_num=1)
                self.logger.info(f"âœ… CityFlowç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ: {config_file}")
            else:
                self.logger.warning("âš ï¸ CityFlowä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç¯å¢ƒ")
                self._init_mock_environment()
        except Exception as e:
            self.logger.error(f"âŒ CityFlowåˆå§‹åŒ–å¤±è´¥: {e}")
            self._init_mock_environment()
    
    def _create_port_config(self) -> str:
        """åˆ›å»ºæ¸¯å£ç‰¹å®šçš„é…ç½®æ–‡ä»¶"""
        topology_dir = project_root / "topologies"
        base_config_file = topology_dir / f"maritime_{self.topology_size}_config.json"
        
        # è¯»å–åŸºç¡€é…ç½®
        with open(base_config_file, 'r') as f:
            config = json.load(f)
        
        # ä¸ºæ¯ä¸ªæ¸¯å£åˆ›å»ºå”¯ä¸€é…ç½®
        port_config_file = topology_dir / f"maritime_{self.topology_size}_{self.port_name}_config.json"
        
        # ä¿®æ”¹é…ç½®
        config["seed"] = 42 + self.port_id * 100  # ä¸åŒæ¸¯å£ä½¿ç”¨ä¸åŒç§å­
        config["roadnetLogFile"] = f"maritime_{self.topology_size}_{self.port_name}_replay_roadnet.json"
        config["replayLogFile"] = f"maritime_{self.topology_size}_{self.port_name}_replay.txt"
        
        # ä¿å­˜æ¸¯å£é…ç½®
        with open(port_config_file, 'w') as f:
            json.dump(config, f, indent=2)
        
        return str(port_config_file)
    
    def _init_mock_environment(self):
        """åˆå§‹åŒ–æ¨¡æ‹Ÿç¯å¢ƒ"""
        self.cityflow_env = None
        self.mock_state = {
            'vehicles': np.random.randint(10, 50),
            'waiting_vehicles': np.random.randint(5, 20),
            'average_speed': np.random.uniform(5, 15),
            'queue_lengths': np.random.randint(0, 10, size=4).tolist()
        }
        self.logger.info("ğŸ”„ ä½¿ç”¨æ¨¡æ‹Ÿç¯å¢ƒ")
    
    def register_with_server(self) -> bool:
        """å‘æœåŠ¡å™¨æ³¨å†Œ"""
        try:
            registration_data = {
                "client_id": self.client_id,
                "port_id": self.port_id,
                "port_name": self.port_name,
                "topology_size": self.topology_size,
                "capabilities": {
                    "cityflow_available": CITYFLOW_AVAILABLE,
                    "node_num": self.node_num,
                    "state_dim": self.state_dim,
                    "action_dim": self.action_dim
                }
            }
            
            response = requests.post(
                f"http://{self.server_host}:{self.server_port}/register",
                json=registration_data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                self.logger.info(f"âœ… æ³¨å†ŒæˆåŠŸ: {result['message']}")
                return True
            else:
                self.logger.error(f"âŒ æ³¨å†Œå¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ æ³¨å†Œå¼‚å¸¸: {e}")
            return False
    
    def get_global_model(self) -> bool:
        """ä»æœåŠ¡å™¨è·å–å…¨å±€æ¨¡å‹"""
        try:
            response = requests.get(
                f"http://{self.server_host}:{self.server_port}/get_global_model",
                params={"client_id": self.client_id},
                timeout=30
            )
            
            if response.status_code == 200:
                model_data = response.json()
                
                if model_data["has_model"]:
                    # æ›´æ–°æœ¬åœ°æ¨¡å‹
                    global_params = model_data["model_params"]
                    self._update_local_model(global_params)
                    self.local_model_version = model_data["version"]
                    self.logger.info(f"ğŸ“¥ è·å–å…¨å±€æ¨¡å‹ v{self.local_model_version}")
                    return True
                else:
                    self.logger.info("ğŸ“­ æœåŠ¡å™¨æš‚æ— å…¨å±€æ¨¡å‹")
                    return True
            else:
                self.logger.error(f"âŒ è·å–å…¨å±€æ¨¡å‹å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ è·å–å…¨å±€æ¨¡å‹å¼‚å¸¸: {e}")
            return False
    
    def _update_local_model(self, global_params: dict):
        """æ›´æ–°æœ¬åœ°æ¨¡å‹å‚æ•°"""
        try:
            # å°†å­—ç¬¦ä¸²å‚æ•°è½¬æ¢å›tensor
            torch_params = {}
            for key, value in global_params.items():
                if isinstance(value, list):
                    torch_params[key] = torch.tensor(value)
                else:
                    torch_params[key] = torch.tensor(value)
            
            self.gat_ppo_agent.set_model_parameters(torch_params)
            self.logger.info("ğŸ”„ æœ¬åœ°æ¨¡å‹å‚æ•°å·²æ›´æ–°")
            
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°æœ¬åœ°æ¨¡å‹å¤±è´¥: {e}")
    
    def train_local_episode(self) -> dict:
        """è®­ç»ƒä¸€ä¸ªæœ¬åœ°episode"""
        self.logger.info(f"ğŸƒ å¼€å§‹æœ¬åœ°è®­ç»ƒ Episode")
        
        # é‡ç½®ç¯å¢ƒ
        state = self._reset_environment()
        episode_reward = 0
        episode_steps = 0
        
        # æ„å»ºGATè¾“å…¥
        node_features = self._build_node_features(state)
        
        for step in range(self.max_steps):
            # GAT-PPOå†³ç­–
            action, action_prob = self.gat_ppo_agent.select_action(node_features)
            
            # ç¯å¢ƒäº¤äº’
            next_state, reward, done, info = self._step_environment(action)
            
            # å…¬å¹³æ€§å¥–åŠ±
            fairness_reward = self.fairness_calculator.calculate_reward(
                base_reward=reward,
                current_state=state,
                action=action,
                agent_id=self.port_id
            )
            
            total_reward = reward + fairness_reward
            
            # æ„å»ºä¸‹ä¸€çŠ¶æ€ç‰¹å¾
            next_node_features = self._build_node_features(next_state)
            
            # å­˜å‚¨ç»éªŒ
            self.gat_ppo_agent.store_experience(
                state=node_features,
                action=action,
                reward=total_reward,
                next_state=next_node_features,
                done=done,
                action_prob=action_prob
            )
            
            # æ›´æ–°çŠ¶æ€
            state = next_state
            node_features = next_node_features
            episode_reward += total_reward
            episode_steps += 1
            
            if done:
                break
        
        # æ‰§è¡ŒPPOæ›´æ–°
        training_stats = self.gat_ppo_agent.update()
        
        episode_result = {
            "episode_reward": episode_reward,
            "episode_steps": episode_steps,
            "avg_reward_per_step": episode_reward / max(episode_steps, 1),
            "port_name": self.port_name,
            "port_id": self.port_id,
            **training_stats
        }
        
        self.training_history.append(episode_result)
        self.logger.info(f"âœ… Episodeå®Œæˆ - å¥–åŠ±: {episode_reward:.2f}, æ­¥æ•°: {episode_steps}")
        
        return episode_result
    
    def upload_local_model(self, training_result: dict) -> bool:
        """ä¸Šä¼ æœ¬åœ°æ¨¡å‹åˆ°æœåŠ¡å™¨"""
        try:
            # è·å–æ¨¡å‹å‚æ•°
            local_params = self.gat_ppo_agent.get_model_parameters()
            
            # è½¬æ¢tensorä¸ºlist (JSONåºåˆ—åŒ–)
            serializable_params = {}
            for key, value in local_params.items():
                if torch.is_tensor(value):
                    serializable_params[key] = value.tolist()
                else:
                    serializable_params[key] = value
            
            upload_data = {
                "client_id": self.client_id,
                "port_id": self.port_id,
                "port_name": self.port_name,
                "model_params": serializable_params,
                "training_result": training_result,
                "local_version": self.local_model_version
            }
            
            response = requests.post(
                f"http://{self.server_host}:{self.server_port}/upload_model",
                json=upload_data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                self.logger.info(f"ğŸ“¤ æ¨¡å‹ä¸Šä¼ æˆåŠŸ: {result['message']}")
                return True
            else:
                self.logger.error(f"âŒ æ¨¡å‹ä¸Šä¼ å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹ä¸Šä¼ å¼‚å¸¸: {e}")
            return False
    
    def _reset_environment(self) -> np.ndarray:
        """é‡ç½®ç¯å¢ƒ"""
        self.current_step = 0
        
        if self.cityflow_env:
            self.cityflow_env.reset()
            return self._get_cityflow_state()
        else:
            self._init_mock_environment()
            return self._get_mock_state()
    
    def _step_environment(self, action: int) -> tuple:
        """ç¯å¢ƒæ­¥è¿›"""
        self.current_step += 1
        
        if self.cityflow_env:
            return self._cityflow_step(action)
        else:
            return self._mock_step(action)
    
    def _cityflow_step(self, action: int) -> tuple:
        """CityFlowç¯å¢ƒæ­¥è¿›"""
        # åº”ç”¨åŠ¨ä½œ
        self._apply_cityflow_action(action)
        
        # æ‰§è¡Œä»¿çœŸæ­¥
        self.cityflow_env.next_step()
        
        # è·å–çŠ¶æ€å’Œå¥–åŠ±
        state = self._get_cityflow_state()
        reward = self._calculate_reward(state, action)
        done = self.current_step >= self.max_steps
        info = {"step": self.current_step, "port": self.port_name}
        
        return state, reward, done, info
    
    def _mock_step(self, action: int) -> tuple:
        """æ¨¡æ‹Ÿç¯å¢ƒæ­¥è¿›"""
        # æ¨¡æ‹ŸåŠ¨ä½œæ•ˆæœ
        effect = {0: 0.95, 1: 1.1, 2: 0.9, 3: 1.05}.get(action, 1.0)
        
        # æ›´æ–°çŠ¶æ€
        self.mock_state['vehicles'] = max(5, int(self.mock_state['vehicles'] * np.random.uniform(0.9, 1.1)))
        self.mock_state['waiting_vehicles'] = max(0, int(self.mock_state['waiting_vehicles'] * effect))
        self.mock_state['average_speed'] = np.clip(
            self.mock_state['average_speed'] * np.random.uniform(0.95, 1.05) * (2-effect), 
            2, 20
        )
        
        state = self._get_mock_state()
        reward = self._calculate_reward(state, action)
        done = self.current_step >= self.max_steps
        info = {"step": self.current_step, "port": self.port_name}
        
        return state, reward, done, info
    
    def _get_cityflow_state(self) -> np.ndarray:
        """è·å–CityFlowçŠ¶æ€"""
        try:
            lane_count = self.cityflow_env.get_lane_vehicle_count()
            lane_waiting = self.cityflow_env.get_lane_waiting_vehicle_count()
            vehicle_speed = self.cityflow_env.get_vehicle_speed()
            
            total_vehicles = sum(lane_count.values()) if lane_count else 0
            total_waiting = sum(lane_waiting.values()) if lane_waiting else 0
            avg_speed = np.mean(list(vehicle_speed.values())) if vehicle_speed else 0
            
            state = np.array([
                total_vehicles / 100.0,
                total_waiting / 50.0,
                avg_speed / 20.0,
                len(lane_count) / 20.0
            ], dtype=np.float32)
            
            return state
        except:
            return np.array([0.1, 0.1, 0.5, 0.2], dtype=np.float32)
    
    def _get_mock_state(self) -> np.ndarray:
        """è·å–æ¨¡æ‹ŸçŠ¶æ€"""
        return np.array([
            self.mock_state['vehicles'] / 100.0,
            self.mock_state['waiting_vehicles'] / 50.0,
            self.mock_state['average_speed'] / 20.0,
            np.mean(self.mock_state['queue_lengths']) / 10.0
        ], dtype=np.float32)
    
    def _apply_cityflow_action(self, action: int):
        """åº”ç”¨CityFlowåŠ¨ä½œ"""
        if not self.cityflow_env:
            return
        try:
            intersections = self.cityflow_env.get_intersection_ids()
            if intersections:
                phase = action % 4  # 4ä¸ªç›¸ä½
                self.cityflow_env.set_tl_phase(intersections[0], phase)
        except:
            pass
    
    def _calculate_reward(self, state: np.ndarray, action: int) -> float:
        """è®¡ç®—å¥–åŠ±"""
        efficiency_reward = (state[2] * 10) - (state[1] * 5)
        throughput_reward = (state[0] * 2) if state[1] < 0.3 else 0
        action_reward = {0: 0, 1: 2, 2: 1, 3: 1.5}.get(action, 0)
        stability_reward = 2 if 0.2 < state[0] < 0.8 and state[1] < 0.4 else 0
        
        return efficiency_reward + throughput_reward + action_reward + stability_reward
    
    def _build_node_features(self, state: np.ndarray) -> torch.Tensor:
        """æ„å»ºGATèŠ‚ç‚¹ç‰¹å¾"""
        node_features = []
        
        for i in range(self.node_num):
            base_features = state.copy()
            
            # ä½ç½®ç¼–ç 
            row = i // int(np.sqrt(self.node_num))
            col = i % int(np.sqrt(self.node_num))
            position_encoding = np.array([row / int(np.sqrt(self.node_num)), 
                                        col / int(np.sqrt(self.node_num))])
            
            combined_features = np.concatenate([base_features, position_encoding])
            node_features.append(combined_features)
        
        return torch.FloatTensor(node_features).unsqueeze(0)
    
    def run_federated_training(self, num_rounds: int = 10, episodes_per_round: int = 3):
        """è¿è¡Œåˆ†å¸ƒå¼è”é‚¦è®­ç»ƒ"""
        self.logger.info(f"ğŸš€ å¼€å§‹åˆ†å¸ƒå¼è”é‚¦è®­ç»ƒ: {num_rounds}è½®, æ¯è½®{episodes_per_round}episodes")
        
        # æ³¨å†Œåˆ°æœåŠ¡å™¨
        if not self.register_with_server():
            self.logger.error("âŒ æœåŠ¡å™¨æ³¨å†Œå¤±è´¥ï¼Œé€€å‡ºè®­ç»ƒ")
            return
        
        for round_num in range(1, num_rounds + 1):
            self.logger.info(f"ğŸ“ å¼€å§‹ç¬¬ {round_num}/{num_rounds} è½®è”é‚¦è®­ç»ƒ")
            
            # 1. è·å–å…¨å±€æ¨¡å‹
            if not self.get_global_model():
                self.logger.warning(f"âš ï¸ è·å–å…¨å±€æ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡å‹ç»§ç»­è®­ç»ƒ")
            
            # 2. æœ¬åœ°è®­ç»ƒ
            round_results = []
            for episode in range(episodes_per_round):
                self.logger.info(f"   Episode {episode + 1}/{episodes_per_round}")
                episode_result = self.train_local_episode()
                round_results.append(episode_result)
            
            # 3. è®¡ç®—è½®æ¬¡ç»Ÿè®¡
            avg_reward = np.mean([r["episode_reward"] for r in round_results])
            round_summary = {
                "round": round_num,
                "episodes": len(round_results),
                "avg_reward": avg_reward,
                "total_steps": sum(r["episode_steps"] for r in round_results),
                "results": round_results
            }
            
            # 4. ä¸Šä¼ æœ¬åœ°æ¨¡å‹
            if not self.upload_local_model(round_summary):
                self.logger.warning(f"âš ï¸ æ¨¡å‹ä¸Šä¼ å¤±è´¥")
            
            self.logger.info(f"âœ… ç¬¬ {round_num} è½®å®Œæˆ - å¹³å‡å¥–åŠ±: {avg_reward:.2f}")
            
            # è½®æ¬¡é—´ç­‰å¾…
            time.sleep(2)
        
        self.logger.info(f"ğŸ‰ åˆ†å¸ƒå¼è”é‚¦è®­ç»ƒå®Œæˆ!")
    
    def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.cityflow_env:
            self.cityflow_env = None
        self.logger.info(f"ğŸ”’ æ¸¯å£å®¢æˆ·ç«¯ {self.port_name} å·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="åˆ†å¸ƒå¼æ¸¯å£å®¢æˆ·ç«¯")
    
    parser.add_argument("--port_id", type=int, required=True, 
                       help="æ¸¯å£ID (0-3)")
    parser.add_argument("--port_name", type=str, required=True,
                       choices=["new_orleans", "south_louisiana", "baton_rouge", "gulfport"],
                       help="æ¸¯å£åç§°")
    parser.add_argument("--server_host", type=str, default="localhost",
                       help="æœåŠ¡å™¨ä¸»æœºåœ°å€")
    parser.add_argument("--server_port", type=int, default=8888,
                       help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--topology", type=str, default="3x3",
                       choices=["3x3", "4x4", "5x5", "6x6"],
                       help="æ‹“æ‰‘å¤§å°")
    parser.add_argument("--rounds", type=int, default=10,
                       help="è”é‚¦å­¦ä¹ è½®æ¬¡")
    parser.add_argument("--episodes", type=int, default=3,
                       help="æ¯è½®episodesæ•°")
    
    args = parser.parse_args()
    
    print(f"ğŸ­ å¯åŠ¨åˆ†å¸ƒå¼æ¸¯å£å®¢æˆ·ç«¯")
    print(f"   æ¸¯å£: {args.port_name} (ID: {args.port_id})")
    print(f"   æœåŠ¡å™¨: {args.server_host}:{args.server_port}")
    print(f"   é…ç½®: {args.topology}, {args.rounds}è½®, æ¯è½®{args.episodes}episodes")
    
    # åˆ›å»ºåˆ†å¸ƒå¼æ¸¯å£å®¢æˆ·ç«¯
    client = DistributedPortClient(
        port_id=args.port_id,
        port_name=args.port_name,
        server_host=args.server_host,
        server_port=args.server_port,
        topology_size=args.topology
    )
    
    try:
        # è¿è¡Œåˆ†å¸ƒå¼è”é‚¦è®­ç»ƒ
        client.run_federated_training(
            num_rounds=args.rounds,
            episodes_per_round=args.episodes
        )
    except KeyboardInterrupt:
        print("âš ï¸ ç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    finally:
        client.close()

if __name__ == "__main__":
    main()