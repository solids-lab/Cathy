#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ä¼˜åŒ–å™¨ - ä¼˜åŒ–è¯„æµ‹å’Œæ¨ç†é€Ÿåº¦
åŒ…æ‹¬å¤šè¿›ç¨‹è¯„æµ‹ã€ç¼“å­˜ä¼˜åŒ–ã€å†…å­˜ç®¡ç†ç­‰
"""
import os
import sys
import time
import json
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp
import psutil
import torch
import numpy as np

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from consistency_test_fixed import eval_one_stage
from curriculum_trainer import CurriculumTrainer, build_agent

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.system_info = self._get_system_info()
        logger.info(f"ç³»ç»Ÿä¿¡æ¯: {self.system_info}")
    
    def _get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        return {
            'cpu_count': mp.cpu_count(),
            'memory_gb': psutil.virtual_memory().total / (1024**3),
            'available_memory_gb': psutil.virtual_memory().available / (1024**3),
            'torch_threads': torch.get_num_threads(),
            'cuda_available': torch.cuda.is_available(),
            'cuda_device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0
        }
    
    def optimize_torch_settings(self):
        """ä¼˜åŒ–PyTorchè®¾ç½®"""
        # è®¾ç½®çº¿ç¨‹æ•°
        optimal_threads = min(self.system_info['cpu_count'], 8)
        torch.set_num_threads(optimal_threads)
        
        # è®¾ç½®å†…å­˜åˆ†é…ç­–ç•¥
        if torch.cuda.is_available():
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
        
        # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†æ¨¡å¼ï¼‰
        torch.set_grad_enabled(False)
        
        logger.info(f"ä¼˜åŒ–PyTorchè®¾ç½®: threads={optimal_threads}")
    
    def profile_single_evaluation(self, port_name: str, stage_name: str, 
                                 n_samples: int = 100) -> Dict:
        """æ€§èƒ½åˆ†æå•æ¬¡è¯„ä¼°"""
        logger.info(f"ğŸ” æ€§èƒ½åˆ†æ: {port_name}/{stage_name}")
        
        # åˆå§‹åŒ–
        start_time = time.time()
        trainer = CurriculumTrainer(port_name)
        agent = build_agent(port_name, device="cpu")
        init_time = time.time() - start_time
        
        # æ‰¾åˆ°å¯¹åº”é˜¶æ®µ
        stage = None
        for s in trainer.curriculum_stages:
            if s.name == stage_name:
                stage = s
                break
        
        if stage is None:
            return {'error': f'æœªæ‰¾åˆ°é˜¶æ®µ: {stage_name}'}
        
        # åŠ è½½æ¨¡å‹
        model_load_start = time.time()
        model_path = f"../../models/curriculum_v2/{port_name}/stage_{stage_name}_best.pt"
        try:
            checkpoint = torch.load(model_path, map_location="cpu")
            if 'model_state_dict' in checkpoint:
                agent.actor_critic.load_state_dict(checkpoint['model_state_dict'])
            else:
                agent.actor_critic.load_state_dict(checkpoint)
            agent.actor_critic.eval()
        except Exception as e:
            return {'error': f'æ¨¡å‹åŠ è½½å¤±è´¥: {e}'}
        
        model_load_time = time.time() - model_load_start
        
        # æ•°æ®ç”Ÿæˆ
        data_gen_start = time.time()
        test_data = trainer._generate_stage_data(stage, num_samples=n_samples)
        data_gen_time = time.time() - data_gen_start
        
        # åŸºçº¿è®¡ç®—
        baseline_start = time.time()
        baseline_data = trainer._generate_stage_data(stage, num_samples=50)
        baseline_rewards = []
        for data in baseline_data:
            reward = trainer._calculate_baseline_reward(data)
            baseline_rewards.append(reward)
        baseline_time = time.time() - baseline_start
        
        # æ¨¡å‹æ¨ç†
        inference_start = time.time()
        inference_times = []
        
        for i, data in enumerate(test_data[:min(50, len(test_data))]):  # åªæµ‹è¯•å‰50ä¸ª
            single_start = time.time()
            
            # æå–ç‰¹å¾
            state = trainer._extract_state_from_data(data)
            node_features, adj_matrix = trainer._extract_graph_features_from_data(data)
            
            # è½¬æ¢ä¸ºå¼ é‡
            state_tensor = torch.as_tensor(state, dtype=torch.float32).unsqueeze(0)
            node_features_tensor = torch.as_tensor(node_features, dtype=torch.float32).unsqueeze(0)
            adj_matrix_tensor = torch.as_tensor(adj_matrix, dtype=torch.float32).unsqueeze(0)
            
            # æ¨ç†
            with torch.no_grad():
                action_probs, value = agent.actor_critic(
                    state_tensor, node_features_tensor, adj_matrix_tensor
                )
            
            single_time = time.time() - single_start
            inference_times.append(single_time * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        
        total_inference_time = time.time() - inference_start
        
        # å®Œæ•´è¯„ä¼°
        eval_start = time.time()
        eval_result = eval_one_stage(trainer, agent, stage, n_samples=n_samples, device="cpu")
        eval_time = time.time() - eval_start
        
        total_time = time.time() - start_time
        
        profile_result = {
            'port': port_name,
            'stage': stage_name,
            'samples': n_samples,
            'timing': {
                'total_time': total_time,
                'init_time': init_time,
                'model_load_time': model_load_time,
                'data_generation_time': data_gen_time,
                'baseline_calculation_time': baseline_time,
                'inference_time': total_inference_time,
                'evaluation_time': eval_time
            },
            'inference_stats': {
                'avg_inference_ms': np.mean(inference_times),
                'std_inference_ms': np.std(inference_times),
                'min_inference_ms': np.min(inference_times),
                'max_inference_ms': np.max(inference_times),
                'samples_tested': len(inference_times)
            },
            'memory_usage': {
                'peak_memory_mb': psutil.Process().memory_info().rss / (1024*1024),
                'available_memory_gb': psutil.virtual_memory().available / (1024**3)
            },
            'evaluation_result': eval_result
        }
        
        return profile_result
    
    def benchmark_parallel_evaluation(self, ports_stages: List[Tuple[str, str]], 
                                    n_samples: int = 100, max_workers: Optional[int] = None) -> Dict:
        """åŸºå‡†æµ‹è¯•å¹¶è¡Œè¯„ä¼°"""
        if max_workers is None:
            max_workers = min(len(ports_stages), self.system_info['cpu_count'] - 1)
        
        logger.info(f"ğŸš€ å¹¶è¡Œè¯„ä¼°åŸºå‡†æµ‹è¯•: {len(ports_stages)} ä¸ªä»»åŠ¡, {max_workers} ä¸ªè¿›ç¨‹")
        
        # ä¸²è¡ŒåŸºå‡†
        serial_start = time.time()
        serial_results = []
        for port, stage in ports_stages[:2]:  # åªæµ‹è¯•å‰2ä¸ª
            result = self.profile_single_evaluation(port, stage, n_samples)
            if 'error' not in result:
                serial_results.append(result)
        serial_time = time.time() - serial_start
        
        # å¹¶è¡ŒåŸºå‡†
        parallel_start = time.time()
        parallel_results = []
        
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {
                executor.submit(self.profile_single_evaluation, port, stage, n_samples): (port, stage)
                for port, stage in ports_stages[:max_workers]  # é™åˆ¶ä»»åŠ¡æ•°
            }
            
            for future in as_completed(future_to_task):
                port, stage = future_to_task[future]
                try:
                    result = future.result()
                    if 'error' not in result:
                        parallel_results.append(result)
                except Exception as e:
                    logger.error(f"å¹¶è¡Œä»»åŠ¡å¤±è´¥ {port}/{stage}: {e}")
        
        parallel_time = time.time() - parallel_start
        
        # è®¡ç®—åŠ é€Ÿæ¯”
        if serial_results and parallel_results:
            avg_serial_time = np.mean([r['timing']['total_time'] for r in serial_results])
            avg_parallel_time = np.mean([r['timing']['total_time'] for r in parallel_results])
            speedup = serial_time / parallel_time if parallel_time > 0 else 0
            efficiency = speedup / max_workers if max_workers > 0 else 0
        else:
            avg_serial_time = avg_parallel_time = speedup = efficiency = 0
        
        benchmark_result = {
            'test_config': {
                'tasks': len(ports_stages),
                'samples_per_task': n_samples,
                'max_workers': max_workers
            },
            'serial_benchmark': {
                'total_time': serial_time,
                'avg_task_time': avg_serial_time,
                'tasks_completed': len(serial_results)
            },
            'parallel_benchmark': {
                'total_time': parallel_time,
                'avg_task_time': avg_parallel_time,
                'tasks_completed': len(parallel_results)
            },
            'performance_metrics': {
                'speedup': speedup,
                'efficiency': efficiency,
                'optimal_workers': max_workers
            },
            'system_info': self.system_info
        }
        
        return benchmark_result
    
    def optimize_evaluation_pipeline(self, results_dir: str) -> Dict:
        """ä¼˜åŒ–è¯„ä¼°æµæ°´çº¿"""
        logger.info("ğŸ”§ ä¼˜åŒ–è¯„ä¼°æµæ°´çº¿...")
        
        # åˆ†æç°æœ‰ç»“æœæ‰¾å‡ºç“¶é¢ˆ
        bottlenecks = self._analyze_bottlenecks(results_dir)
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = self._generate_optimization_recommendations(bottlenecks)
        
        # å®æ–½ä¼˜åŒ–
        optimizations_applied = self._apply_optimizations(recommendations)
        
        return {
            'bottlenecks': bottlenecks,
            'recommendations': recommendations,
            'optimizations_applied': optimizations_applied
        }
    
    def _analyze_bottlenecks(self, results_dir: str) -> Dict:
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        # è¿™é‡Œå¯ä»¥åˆ†ææ—¥å¿—æ–‡ä»¶ã€æ€§èƒ½æ•°æ®ç­‰
        # ç®€åŒ–å®ç°
        return {
            'data_generation': 'medium',
            'model_loading': 'low',
            'inference': 'high',
            'baseline_calculation': 'medium'
        }
    
    def _generate_optimization_recommendations(self, bottlenecks: Dict) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if bottlenecks.get('inference') == 'high':
            recommendations.extend([
                "ä½¿ç”¨TorchScriptç¼–è¯‘æ¨¡å‹ä»¥æå‡æ¨ç†é€Ÿåº¦",
                "æ‰¹é‡å¤„ç†æ¨ç†è¯·æ±‚",
                "ä½¿ç”¨GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰",
                "ä¼˜åŒ–æ¨¡å‹æ¶æ„å‡å°‘è®¡ç®—å¤æ‚åº¦"
            ])
        
        if bottlenecks.get('data_generation') in ['medium', 'high']:
            recommendations.extend([
                "é¢„ç”Ÿæˆå’Œç¼“å­˜æµ‹è¯•æ•°æ®",
                "ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®ç»“æ„",
                "å¹¶è¡ŒåŒ–æ•°æ®ç”Ÿæˆè¿‡ç¨‹"
            ])
        
        if bottlenecks.get('baseline_calculation') in ['medium', 'high']:
            recommendations.extend([
                "ç¼“å­˜åŸºçº¿è®¡ç®—ç»“æœ",
                "ä½¿ç”¨è¿‘ä¼¼ç®—æ³•åŠ é€ŸåŸºçº¿è®¡ç®—",
                "å‡å°‘åŸºçº¿æ ·æœ¬æ•°é‡"
            ])
        
        return recommendations
    
    def _apply_optimizations(self, recommendations: List[str]) -> List[str]:
        """åº”ç”¨ä¼˜åŒ–æªæ–½"""
        applied = []
        
        # ä¼˜åŒ–PyTorchè®¾ç½®
        self.optimize_torch_settings()
        applied.append("ä¼˜åŒ–PyTorchçº¿ç¨‹å’Œå†…å­˜è®¾ç½®")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['OMP_NUM_THREADS'] = str(min(self.system_info['cpu_count'], 8))
        os.environ['MKL_NUM_THREADS'] = str(min(self.system_info['cpu_count'], 8))
        applied.append("è®¾ç½®OpenMPå’ŒMKLçº¿ç¨‹æ•°")
        
        return applied
    
    def create_performance_report(self, profile_results: List[Dict], 
                                benchmark_result: Dict, output_path: str):
        """åˆ›å»ºæ€§èƒ½æŠ¥å‘Š"""
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'system_info': self.system_info,
            'profile_results': profile_results,
            'benchmark_result': benchmark_result,
            'summary': self._generate_performance_summary(profile_results, benchmark_result)
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        return report
    
    def _generate_performance_summary(self, profile_results: List[Dict], 
                                    benchmark_result: Dict) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æ‘˜è¦"""
        if not profile_results:
            return {}
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_total_time = np.mean([r['timing']['total_time'] for r in profile_results])
        avg_inference_time = np.mean([r['inference_stats']['avg_inference_ms'] for r in profile_results])
        avg_memory_usage = np.mean([r['memory_usage']['peak_memory_mb'] for r in profile_results])
        
        summary = {
            'avg_evaluation_time_seconds': avg_total_time,
            'avg_inference_time_ms': avg_inference_time,
            'avg_memory_usage_mb': avg_memory_usage,
            'parallel_speedup': benchmark_result.get('performance_metrics', {}).get('speedup', 0),
            'parallel_efficiency': benchmark_result.get('performance_metrics', {}).get('efficiency', 0),
            'recommendations': [
                f"å¹³å‡è¯„ä¼°æ—¶é—´: {avg_total_time:.2f}ç§’",
                f"å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.2f}æ¯«ç§’",
                f"å¹¶è¡ŒåŠ é€Ÿæ¯”: {benchmark_result.get('performance_metrics', {}).get('speedup', 0):.2f}x"
            ]
        }
        
        return summary

def main():
    parser = argparse.ArgumentParser(description="æ€§èƒ½ä¼˜åŒ–å™¨")
    parser.add_argument("--profile", action="store_true", help="æ€§èƒ½åˆ†ææ¨¡å¼")
    parser.add_argument("--benchmark", action="store_true", help="åŸºå‡†æµ‹è¯•æ¨¡å¼")
    parser.add_argument("--port", help="æ¸¯å£åç§°ï¼ˆæ€§èƒ½åˆ†æç”¨ï¼‰")
    parser.add_argument("--stage", help="é˜¶æ®µåç§°ï¼ˆæ€§èƒ½åˆ†æç”¨ï¼‰")
    parser.add_argument("--samples", type=int, default=100, help="æµ‹è¯•æ ·æœ¬æ•°")
    parser.add_argument("--max-workers", type=int, help="æœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•°")
    parser.add_argument("--output", default="../../reports/performance_report.json", 
                       help="è¾“å‡ºæŠ¥å‘Šè·¯å¾„")
    
    args = parser.parse_args()
    
    optimizer = PerformanceOptimizer()
    
    if args.profile and args.port and args.stage:
        # å•ä¸ªé˜¶æ®µæ€§èƒ½åˆ†æ
        logger.info(f"ğŸ” æ€§èƒ½åˆ†æ: {args.port}/{args.stage}")
        result = optimizer.profile_single_evaluation(args.port, args.stage, args.samples)
        
        if 'error' in result:
            logger.error(f"æ€§èƒ½åˆ†æå¤±è´¥: {result['error']}")
        else:
            print("\nğŸ“Š æ€§èƒ½åˆ†æç»“æœ:")
            print(f"æ€»æ—¶é—´: {result['timing']['total_time']:.2f}ç§’")
            print(f"æ¨¡å‹åŠ è½½: {result['timing']['model_load_time']:.2f}ç§’")
            print(f"æ•°æ®ç”Ÿæˆ: {result['timing']['data_generation_time']:.2f}ç§’")
            print(f"æ¨ç†æ—¶é—´: {result['timing']['inference_time']:.2f}ç§’")
            print(f"å¹³å‡å•æ¬¡æ¨ç†: {result['inference_stats']['avg_inference_ms']:.2f}æ¯«ç§’")
            print(f"å†…å­˜ä½¿ç”¨: {result['memory_usage']['peak_memory_mb']:.1f}MB")
    
    elif args.benchmark:
        # å¹¶è¡ŒåŸºå‡†æµ‹è¯•
        # ä½¿ç”¨ä¸€äº›ç¤ºä¾‹ä»»åŠ¡
        test_tasks = [
            ("baton_rouge", "åŸºç¡€é˜¶æ®µ"),
            ("baton_rouge", "ä¸­çº§é˜¶æ®µ"),
            ("new_orleans", "åŸºç¡€é˜¶æ®µ"),
            ("new_orleans", "åˆçº§é˜¶æ®µ")
        ]
        
        logger.info("ğŸš€ å¹¶è¡ŒåŸºå‡†æµ‹è¯•")
        benchmark_result = optimizer.benchmark_parallel_evaluation(
            test_tasks, args.samples, args.max_workers
        )
        
        print("\nğŸ“Š å¹¶è¡ŒåŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"ä¸²è¡Œæ—¶é—´: {benchmark_result['serial_benchmark']['total_time']:.2f}ç§’")
        print(f"å¹¶è¡Œæ—¶é—´: {benchmark_result['parallel_benchmark']['total_time']:.2f}ç§’")
        print(f"åŠ é€Ÿæ¯”: {benchmark_result['performance_metrics']['speedup']:.2f}x")
        print(f"æ•ˆç‡: {benchmark_result['performance_metrics']['efficiency']:.2f}")
        
        # ä¿å­˜åŸºå‡†æµ‹è¯•æŠ¥å‘Š
        optimizer.create_performance_report([], benchmark_result, args.output)
    
    else:
        # å®Œæ•´æ€§èƒ½ä¼˜åŒ–åˆ†æ
        logger.info("ğŸ”§ å®Œæ•´æ€§èƒ½ä¼˜åŒ–åˆ†æ")
        
        # åˆ†æå‡ ä¸ªä»£è¡¨æ€§é˜¶æ®µ
        test_cases = [
            ("baton_rouge", "åŸºç¡€é˜¶æ®µ"),
            ("new_orleans", "åˆçº§é˜¶æ®µ")
        ]
        
        profile_results = []
        for port, stage in test_cases:
            result = optimizer.profile_single_evaluation(port, stage, args.samples)
            if 'error' not in result:
                profile_results.append(result)
        
        # å¹¶è¡ŒåŸºå‡†æµ‹è¯•
        benchmark_result = optimizer.benchmark_parallel_evaluation(test_cases, args.samples)
        
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        report = optimizer.create_performance_report(profile_results, benchmark_result, args.output)
        
        print("\nğŸ“‹ æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š:")
        summary = report['summary']
        for rec in summary.get('recommendations', []):
            print(f"  â€¢ {rec}")

if __name__ == "__main__":
    main()