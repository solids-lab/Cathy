#!/usr/bin/env python3
"""
GATå°è£…å™¨ï¼šå°†ç°æœ‰çš„pytorch-GATé€‚é…åˆ°æµ·äº‹äº¤é€šåœºæ™¯
è§£å†³å¯¼å…¥è·¯å¾„å’Œå…¼å®¹æ€§é—®é¢˜
"""

import sys
import os
import torch
import torch.nn as nn
import numpy as np
from typing import Tuple, Dict, List, Optional
from pathlib import Path

# å…¨å±€æ ‡å¿—ï¼Œç¡®ä¿è­¦å‘Šåªæ˜¾ç¤ºä¸€æ¬¡
_GAT_WARNING_SHOWN = False

def show_gat_warning_once(message: str):
    """åªæ˜¾ç¤ºä¸€æ¬¡GATè­¦å‘Š"""
    global _GAT_WARNING_SHOWN
    if not _GAT_WARNING_SHOWN:
        print(f"âš ï¸ {message}")
        _GAT_WARNING_SHOWN = True


# åŠ¨æ€æ·»åŠ GATé¡¹ç›®è·¯å¾„
def setup_gat_path():
    """è®¾ç½®GATé¡¹ç›®è·¯å¾„"""
    # è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•
    current_dir = Path(__file__).parent

    # å¯èƒ½çš„GATè·¯å¾„
    possible_gat_paths = [
        current_dir / "../../FedML/externals/pytorch-GAT",
        current_dir / "../../../FedML/externals/pytorch-GAT",
        current_dir / "../../externals/pytorch-GAT",
    ]

    for gat_path in possible_gat_paths:
        gat_path = gat_path.resolve()
        if gat_path.exists() and (gat_path / "models").exists():
            sys.path.insert(0, str(gat_path))
            return str(gat_path)

    raise ImportError(f"æ— æ³•æ‰¾åˆ°GATé¡¹ç›®è·¯å¾„ã€‚è¯·ç¡®ä¿pytorch-GATé¡¹ç›®åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€: {possible_gat_paths}")


# è®¾ç½®GATè·¯å¾„
try:
    GAT_PROJECT_PATH = setup_gat_path()
    print(f"âœ… GATé¡¹ç›®è·¯å¾„: {GAT_PROJECT_PATH}")
except ImportError as e:
    print(f"âŒ GATè·¯å¾„è®¾ç½®å¤±è´¥: {e}")
    # åˆ›å»ºå¤‡ç”¨å®ç°
    GAT_PROJECT_PATH = None

# å¯¼å…¥GATç›¸å…³æ¨¡å—
if GAT_PROJECT_PATH:
    try:
        from models.definitions.GAT import GAT
        from utils.constants import LayerType

        GAT_AVAILABLE = True
        print("âœ… GATæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ GATæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        GAT_AVAILABLE = False
else:
    GAT_AVAILABLE = False

# å¦‚æœGATä¸å¯ç”¨ï¼Œåˆ›å»ºå¤‡ç”¨å®ç°
if not GAT_AVAILABLE:
    show_gat_warning_once("ä½¿ç”¨å¤‡ç”¨GATå®ç°")


    class LayerType:
        """LayerTypeæšä¸¾å¤‡ç”¨å®ç°"""
        IMP1 = 0
        IMP2 = 1
        IMP3 = 2


    class GAT(nn.Module):
        """ç®€åŒ–çš„GATå¤‡ç”¨å®ç°"""

        def __init__(self, num_of_layers, num_heads_per_layer, num_features_per_layer, **kwargs):
            super().__init__()
            self.num_features = num_features_per_layer
            self.num_layers = num_of_layers

            # ç®€å•çš„çº¿æ€§å±‚åºåˆ—
            layers = []
            for i in range(num_of_layers):
                in_features = num_features_per_layer[i] * (num_heads_per_layer[i] if i > 0 else 1)
                out_features = num_features_per_layer[i + 1]

                layers.extend([
                    nn.Linear(in_features, out_features),
                    nn.ReLU() if i < num_of_layers - 1 else nn.Identity()
                ])

            self.layers = nn.Sequential(*layers)

        def forward(self, data):
            node_features, adjacency_matrix = data
            return self.layers(node_features)


class MaritimeGATEncoder(nn.Module):
    """
    æµ·äº‹äº¤é€šåœºæ™¯çš„GATç¼–ç å™¨
    é€‚é…ç°æœ‰GATå®ç°åˆ°æˆ‘ä»¬çš„4èŠ‚ç‚¹æµ·äº‹ç½‘ç»œ
    """

    def __init__(self,
                 node_feature_dim: int = 5,
                 hidden_dim: int = 64,
                 output_dim: int = 32,
                 num_heads: int = 4,
                 dropout: float = 0.1,
                 use_backup_gat: bool = False):
        super().__init__()

        self.node_feature_dim = node_feature_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.use_backup_gat = use_backup_gat or not GAT_AVAILABLE

        if self.use_backup_gat:
            # é™é»˜æ¨¡å¼ï¼šä¸å†é‡å¤æ˜¾ç¤ºè­¦å‘Š
            # ä½¿ç”¨å¤‡ç”¨GATå®ç°
            self.gat = GAT(
                num_of_layers=2,
                num_heads_per_layer=[num_heads, 1],
                num_features_per_layer=[node_feature_dim, hidden_dim, output_dim]
            )
        else:
            # ä½¿ç”¨åŸå§‹GATå®ç°
            self.gat = GAT(
                num_of_layers=2,
                num_heads_per_layer=[num_heads, 1],  # ç¬¬ä¸€å±‚å¤šå¤´ï¼Œæœ€åä¸€å±‚å•å¤´
                num_features_per_layer=[node_feature_dim, hidden_dim, output_dim],
                add_skip_connection=True,
                bias=True,
                dropout=dropout,
                layer_type=LayerType.IMP2,  # ä½¿ç”¨å®ç°2ï¼ˆå¹³è¡¡æ€§èƒ½å’Œç†è§£åº¦ï¼‰
                log_attention_weights=True  # è®°å½•æ³¨æ„åŠ›æƒé‡ç”¨äºåˆ†æ
            )

        # å›¾çº§åˆ«ç‰¹å¾èšåˆ
        self.graph_aggregator = nn.Sequential(
            nn.Linear(output_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, output_dim),
            nn.LayerNorm(output_dim)
        )

        # ä½ç½®ç¼–ç ï¼ˆå¯é€‰ï¼‰
        self.position_encoding = nn.Parameter(torch.randn(4, output_dim) * 0.1)

    def forward(self, node_features: torch.Tensor,
                adjacency_matrix: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            node_features: [num_nodes, node_feature_dim]
            adjacency_matrix: [num_nodes, num_nodes]
        Returns:
            node_embeddings: [num_nodes, output_dim]
            graph_embedding: [output_dim]
        """

        # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
        if node_features.dim() == 1:
            node_features = node_features.unsqueeze(0)
        if adjacency_matrix.dim() == 2 and adjacency_matrix.size(0) != node_features.size(0):
            # å¦‚æœé‚»æ¥çŸ©é˜µç»´åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨å…¨è¿æ¥
            num_nodes = node_features.size(0)
            adjacency_matrix = torch.ones(num_nodes, num_nodes, device=node_features.device)

        # è½¬æ¢ä¸ºGATæœŸæœ›çš„æ ¼å¼ (node_features, topology)
        gat_input = (node_features, adjacency_matrix)

        try:
            # é€šè¿‡GATç½‘ç»œ
            gat_output = self.gat(gat_input)
            
            # GATå¯èƒ½è¿”å›tupleï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºnode embeddings
            if isinstance(gat_output, tuple):
                node_embeddings = gat_output[0]
            else:
                node_embeddings = gat_output

            # æ·»åŠ ä½ç½®ç¼–ç 
            if node_embeddings.size(0) == 4:  # 4ä¸ªèŠ‚ç‚¹çš„æƒ…å†µ
                node_embeddings = node_embeddings + self.position_encoding

            # å›¾çº§åˆ«èšåˆï¼ˆä½¿ç”¨æ³¨æ„åŠ›åŠ æƒå¹³å‡ï¼‰
            attention_weights = self._compute_graph_attention(node_embeddings)
            graph_embedding = torch.sum(attention_weights.unsqueeze(-1) * node_embeddings, dim=0)
            graph_embedding = self.graph_aggregator(graph_embedding)

        except Exception as e:
            print(f"GATå‰å‘ä¼ æ’­å‡ºé”™: {e}")
            # å¤‡ç”¨å¤„ç†ï¼šç®€å•çš„MLP
            node_embeddings = self._backup_forward(node_features)
            graph_embedding = torch.mean(node_embeddings, dim=0)
            graph_embedding = self.graph_aggregator(graph_embedding)

        return node_embeddings, graph_embedding

    def _compute_graph_attention(self, node_embeddings: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—å›¾çº§åˆ«æ³¨æ„åŠ›æƒé‡"""
        # ç®€å•çš„æ³¨æ„åŠ›æœºåˆ¶
        attention_scores = torch.sum(node_embeddings ** 2, dim=-1)
        attention_weights = torch.softmax(attention_scores, dim=0)
        return attention_weights

    def _backup_forward(self, node_features: torch.Tensor) -> torch.Tensor:
        """å¤‡ç”¨å‰å‘ä¼ æ’­ï¼ˆå½“GATå¤±è´¥æ—¶ï¼‰"""
        # ç®€å•çš„MLPå¤„ç†
        weight1 = torch.randn(node_features.size(-1), self.hidden_dim)
        bias1 = torch.zeros(self.hidden_dim)
        hidden = torch.relu(torch.nn.functional.linear(node_features, weight1.T, bias1))
        
        weight2 = torch.randn(self.hidden_dim, self.output_dim)
        bias2 = torch.zeros(self.output_dim)
        output = torch.nn.functional.linear(hidden, weight2.T, bias2)
        return output


class MaritimeStateBuilder:
    """
    æµ·äº‹çŠ¶æ€æ„å»ºå™¨ï¼šå°†äº¤é€šçŠ¶æ€è½¬æ¢ä¸ºå›¾æ•°æ®
    """

    def __init__(self, num_nodes: int = 4):
        self.num_nodes = num_nodes

        # å›ºå®šçš„èˆªé“æ‹“æ‰‘ï¼ˆ4èŠ‚ç‚¹ç½‘ç»œï¼‰
        self.adjacency_matrix = self._build_maritime_topology()

        # ç‰¹å¾æ ‡å‡†åŒ–å‚æ•°
        self.feature_stats = {
            'waiting_ships': {'mean': 10.0, 'std': 5.0},
            'throughput': {'mean': 5.0, 'std': 3.0},
            'waiting_time': {'mean': 15.0, 'std': 10.0},
            'signal_phase': {'mean': 0.5, 'std': 0.5},
            'weather_condition': {'mean': 0.8, 'std': 0.2}
        }

    @staticmethod
    def _build_maritime_topology() -> torch.Tensor:
        """æ„å»ºæµ·äº‹ç½‘ç»œæ‹“æ‰‘"""
        # å®šä¹‰4èŠ‚ç‚¹ç½‘ç»œçš„è¿æ¥æ¨¡å¼
        # 0: NodeA (ä¸»å…¥å£), 1: NodeB (å·¥ä¸šè¿æ²³), 2: NodeC (ä¸­æ¸¸æ®µ), 3: NodeD (å¤–æµ·é”šåœ°)
        adj = torch.tensor([
            [1.0, 1.0, 1.0, 0.8],  # NodeAè¿æ¥åº¦
            [1.0, 1.0, 0.6, 1.0],  # NodeBè¿æ¥åº¦
            [1.0, 0.6, 1.0, 0.9],  # NodeCè¿æ¥åº¦
            [0.8, 1.0, 0.9, 1.0],  # NodeDè¿æ¥åº¦
        ], dtype=torch.float32)

        return adj

    def build_state(self, maritime_observations: Dict[str, Dict]) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ„å»ºå›¾çŠ¶æ€

        Args:
            maritime_observations: {
                'NodeA': {'waiting_ships': 5, 'throughput': 3, 'waiting_time': 12, ...},
                'NodeB': {'waiting_ships': 8, 'throughput': 2, 'waiting_time': 18, ...},
                ...
            }
        Returns:
            node_features: [num_nodes, feature_dim]
            adjacency_matrix: [num_nodes, num_nodes]
        """

        node_features = []

        # æŒ‰èŠ‚ç‚¹é¡ºåºæå–ç‰¹å¾
        node_names = ['NodeA', 'NodeB', 'NodeC', 'NodeD']

        for i, node_id in enumerate(node_names[:self.num_nodes]):
            if node_id in maritime_observations:
                obs = maritime_observations[node_id]

                # æå–å’Œæ ‡å‡†åŒ–ç‰¹å¾
                features = self._extract_and_normalize_features(obs)
            else:
                # é»˜è®¤ç‰¹å¾ï¼ˆå½’ä¸€åŒ–åçš„ï¼‰
                features = [0.0, 0.0, 0.0, 0.0, 1.0]

            node_features.append(features)

        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„èŠ‚ç‚¹
        while len(node_features) < self.num_nodes:
            node_features.append([0.0, 0.0, 0.0, 0.0, 1.0])

        node_features = torch.tensor(node_features, dtype=torch.float32)

        return node_features, self.adjacency_matrix

    def _extract_and_normalize_features(self, obs: Dict) -> List[float]:
        """æå–å’Œæ ‡å‡†åŒ–ç‰¹å¾"""
        features = []
        feature_names = ['waiting_ships', 'throughput', 'waiting_time', 'signal_phase', 'weather_condition']

        for feature_name in feature_names:
            raw_value = obs.get(feature_name, 0.0)

            if feature_name in self.feature_stats:
                # Z-scoreæ ‡å‡†åŒ–
                stats = self.feature_stats[feature_name]
                normalized_value = (raw_value - stats['mean']) / stats['std']
                # è£å‰ªåˆ°åˆç†èŒƒå›´
                normalized_value = max(-3.0, min(3.0, normalized_value))
            else:
                normalized_value = float(raw_value)

            features.append(normalized_value)

        return features

    def update_feature_stats(self, observations_history: List[Dict[str, Dict]]):
        """åŸºäºå†å²æ•°æ®æ›´æ–°ç‰¹å¾ç»Ÿè®¡"""
        if not observations_history:
            return

        # æ”¶é›†æ‰€æœ‰ç‰¹å¾å€¼
        all_features = {name: [] for name in self.feature_stats.keys()}

        for obs_batch in observations_history:
            for node_data in obs_batch.values():
                for feature_name in all_features.keys():
                    if feature_name in node_data:
                        all_features[feature_name].append(node_data[feature_name])

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        for feature_name, values in all_features.items():
            if values:
                self.feature_stats[feature_name]['mean'] = np.mean(values)
                self.feature_stats[feature_name]['std'] = max(np.std(values), 1e-6)  # é¿å…é™¤é›¶


def test_maritime_gat():
    """æµ‹è¯•æµ·äº‹GATç¼–ç å™¨"""

    print("ğŸ§ª æµ‹è¯•æµ·äº‹GATç¼–ç å™¨")
    print("=" * 50)

    # åˆ›å»ºGATç¼–ç å™¨
    gat_encoder = MaritimeGATEncoder(
        node_feature_dim=5,
        hidden_dim=32,
        output_dim=16,
        num_heads=4
    )

    print(f"âœ… GATç¼–ç å™¨åˆ›å»ºæˆåŠŸ")
    print(f"  è¾“å…¥ç»´åº¦: {gat_encoder.node_feature_dim}")
    print(f"  éšè—ç»´åº¦: {gat_encoder.hidden_dim}")
    print(f"  è¾“å‡ºç»´åº¦: {gat_encoder.output_dim}")
    print(f"  ä½¿ç”¨å¤‡ç”¨å®ç°: {gat_encoder.use_backup_gat}")

    # åˆ›å»ºçŠ¶æ€æ„å»ºå™¨
    state_builder = MaritimeStateBuilder()

    # æ¨¡æ‹Ÿæµ·äº‹è§‚æµ‹æ•°æ®
    maritime_observations = {
        'NodeA': {'waiting_ships': 5, 'throughput': 3, 'waiting_time': 12, 'signal_phase': 1, 'weather_condition': 0.8},
        'NodeB': {'waiting_ships': 8, 'throughput': 2, 'waiting_time': 18, 'signal_phase': 0, 'weather_condition': 0.8},
        'NodeC': {'waiting_ships': 3, 'throughput': 1, 'waiting_time': 8, 'signal_phase': 1, 'weather_condition': 0.8},
        'NodeD': {'waiting_ships': 6, 'throughput': 4, 'waiting_time': 15, 'signal_phase': 0, 'weather_condition': 0.8},
    }

    print(f"\nğŸ“Š æµ‹è¯•æ•°æ®:")
    for node, data in maritime_observations.items():
        print(f"  {node}: {data}")

    # æ„å»ºå›¾çŠ¶æ€
    node_features, adjacency_matrix = state_builder.build_state(maritime_observations)

    print(f"\nğŸ” å›¾çŠ¶æ€:")
    print(f"  èŠ‚ç‚¹ç‰¹å¾å½¢çŠ¶: {node_features.shape}")
    print(f"  é‚»æ¥çŸ©é˜µå½¢çŠ¶: {adjacency_matrix.shape}")
    print(f"  èŠ‚ç‚¹ç‰¹å¾ (æ ‡å‡†åŒ–å):\n{node_features}")
    print(f"  é‚»æ¥çŸ©é˜µ:\n{adjacency_matrix}")

    # GATå‰å‘ä¼ æ’­
    print(f"\nğŸš€ GATå‰å‘ä¼ æ’­:")
    try:
        with torch.no_grad():
            node_embeddings, graph_embedding = gat_encoder(node_features, adjacency_matrix)

            print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"  èŠ‚ç‚¹åµŒå…¥å½¢çŠ¶: {node_embeddings.shape}")
            print(f"  å›¾åµŒå…¥å½¢çŠ¶: {graph_embedding.shape}")
            print(f"  èŠ‚ç‚¹åµŒå…¥èŒƒå›´: [{torch.min(node_embeddings):.3f}, {torch.max(node_embeddings):.3f}]")
            print(f"  å›¾åµŒå…¥èŒƒå›´: [{torch.min(graph_embedding):.3f}, {torch.max(graph_embedding):.3f}]")

    except Exception as e:
        print(f"  âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    # æµ‹è¯•æ‰¹é‡å¤„ç†
    print(f"\nğŸ“¦ æµ‹è¯•æ‰¹é‡å¤„ç†:")
    try:
        batch_observations = [maritime_observations for _ in range(3)]

        for i, obs in enumerate(batch_observations):
            node_features, adjacency_matrix = state_builder.build_state(obs)
            node_embeddings, graph_embedding = gat_encoder(node_features, adjacency_matrix)
            print(f"  æ‰¹æ¬¡ {i + 1}: èŠ‚ç‚¹åµŒå…¥ {node_embeddings.shape}, å›¾åµŒå…¥ {graph_embedding.shape}")

        print(f"  âœ… æ‰¹é‡å¤„ç†æˆåŠŸ")

    except Exception as e:
        print(f"  âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")

    print(f"\nâœ… æµ·äº‹GATç¼–ç å™¨æµ‹è¯•å®Œæˆï¼")
    return True


def check_gat_installation():
    """æ£€æŸ¥GATå®‰è£…çŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥GATå®‰è£…çŠ¶æ€")
    print("=" * 40)

    print(f"GATé¡¹ç›®è·¯å¾„: {GAT_PROJECT_PATH}")
    print(f"GATå¯ç”¨æ€§: {GAT_AVAILABLE}")

    if GAT_AVAILABLE:
        print("âœ… åŸå§‹GATå®ç°å¯ç”¨")
        try:
            # æµ‹è¯•GATå¯¼å…¥
            test_gat = GAT(
                num_of_layers=1,
                num_heads_per_layer=[2],
                num_features_per_layer=[5, 8]
            )
            print("âœ… GATæ¨¡å—æµ‹è¯•æˆåŠŸ")
        except Exception as e:
            print(f"âŒ GATæ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
    else:
        if not _GAT_WARNING_SHOWN:
            show_gat_warning_once("ä½¿ç”¨å¤‡ç”¨GATå®ç°")
            print("  å»ºè®®: æ£€æŸ¥pytorch-GATé¡¹ç›®æ˜¯å¦æ­£ç¡®æ”¾ç½®åœ¨FedML/externals/ç›®å½•ä¸‹")


if __name__ == "__main__":
    # æ£€æŸ¥GATå®‰è£…
    check_gat_installation()

    print("\n" + "=" * 60 + "\n")

    # è¿è¡Œæµ‹è¯•
    test_maritime_gat()