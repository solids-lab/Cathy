#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Flower è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯ï¼ˆå®¹é”™ç‰ˆï¼‰
- è®­ç»ƒé˜¶æ®µï¼šä»»ä½•æŒ‡æ ‡ç¼ºå¤±(None)éƒ½ä¸ä¼šæŠ¥é”™
- è¯„ä¼°é˜¶æ®µï¼šæ²¿ç”¨ FedAvgClient.evaluate()ï¼Œä½†ä¹Ÿåšå®¹é”™
- å¯åŠ¨æ–¹å¼ï¼šstart_client(..., client=...to_client())
"""

import os
import sys
import logging
from typing import Dict, List, Tuple, Optional

import numpy as np
import flwr as fl

# æŠŠé¡¹ç›®æ ¹åŠ å…¥ sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.federated.fedavg_client import FedAvgClient  # noqa

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def _safe_float(x, default=None):
    """æŠŠ x å®‰å…¨è½¬ä¸º floatã€‚x ä¸º None æˆ–æ— æ³•è½¬æ¢æ—¶ï¼Œè¿”å› defaultã€‚"""
    try:
        return float(x) if x is not None else default
    except Exception:
        return default


class FlowerClient(fl.client.NumPyClient):
    """Flower NumPyClient å°è£…"""

    def __init__(
        self,
        port: str,
        server_address: str = "localhost:8080",
        init_weights: Optional[str] = None,
        episodes: int = 8,
        ppo_epochs: int = 4,
        batch_size: int = 64,
        entropy_coef: float = 0.01,
    ):
        self.port = port
        self.server_address = server_address
        self.init_weights = init_weights
        self.episodes = episodes
        self.ppo_epochs = ppo_epochs
        self.batch_size = batch_size
        self.entropy_coef = entropy_coef

        self.client = FedAvgClient(port=port, init_weights=init_weights)

        # å›ºå®šå‚æ•°é”®é¡ºåº
        self.param_keys = list(self.client.get_parameters().keys())
        logger.info(f"ğŸ”‘ å‚æ•°é”®é¡ºåº: {self.param_keys}")
        logger.info(
            f"âš™ï¸ è®­ç»ƒå‚æ•°: episodes={episodes}, ppo_epochs={ppo_epochs}, "
            f"batch_size={batch_size}, entropy_coef={entropy_coef}"
        )

    # ---------- Flower NumPyClient æ¥å£ ----------

    def get_parameters(self, config: Dict[str, str]) -> List[np.ndarray]:
        params = self.client.get_parameters()
        return [params[k] for k in self.param_keys]

    def set_parameters(self, parameters: List[np.ndarray]) -> None:
        params_dict = {k: v for k, v in zip(self.param_keys, parameters)}
        self.client.set_parameters(params_dict)

    def fit(
        self, parameters: List[np.ndarray], config: Dict[str, str]
    ) -> Tuple[List[np.ndarray], int, Dict]:
        """æœ¬åœ°è®­ç»ƒï¼ˆå®¹é”™æ”¶é›†æŒ‡æ ‡ï¼Œä¸å¯¹ None åš float()ï¼‰"""
        # ä¸‹å‘å…¨å±€å‚æ•°
        self.set_parameters(parameters)

        logger.info(f"ğŸ‹ï¸ å¼€å§‹æœ¬åœ°è®­ç»ƒ - æ¸¯å£: {self.port}")
        logger.info(
            f"ğŸ“Š è®­ç»ƒé…ç½®: episodes={self.episodes}, ppo_epochs={self.ppo_epochs}, "
            f"batch_size={self.batch_size}"
        )

        # è¿è¡Œæœ¬åœ°è®­ç»ƒï¼Œå¯èƒ½è¿”å› None æˆ–ç¼ºå­—æ®µ
        train_stats = self.client.train(
            episodes=self.episodes,
            ppo_epochs=self.ppo_epochs,
            batch_size=self.batch_size,
            entropy_coef=self.entropy_coef,
        ) or {}

        # è®­ç»ƒåå‚æ•°
        new_params = self.get_parameters(config)

        # ---- å…³é”®ï¼šå®¹é”™æ•´ç†æŒ‡æ ‡ ----
        # æ³¨æ„ï¼šdict.get("x", 0.0) å¯¹â€œé”®å­˜åœ¨ä½†å€¼ä¸º Noneâ€çš„æƒ…å†µä¸ä¼šç”¨åˆ°é»˜è®¤å€¼
        # æ‰€ä»¥å¿…é¡»å…ˆå–å‡ºåŸå€¼ï¼Œå† _safe_float(x, default)ã€‚
        loss = _safe_float(train_stats.get("loss"), None)
        reward = _safe_float(
            train_stats.get("avg_reward", train_stats.get("reward")), None
        )
        success_rate = _safe_float(
            train_stats.get("success_rate", train_stats.get("accuracy")), None
        )
        num_samples = int(
            train_stats.get(
                "num_samples",
                max(1, int(self.batch_size))
                * max(1, int(self.episodes))
                * max(1, int(self.ppo_epochs)),
            )
        )

        metrics: Dict[str, float] = {
            "port": self.port,
            "episodes": self.episodes,
            "ppo_epochs": self.ppo_epochs,
            "batch_size": self.batch_size,
            "entropy_coef": self.entropy_coef,
            "num_samples": num_samples,
        }
        if loss is not None:
            metrics["loss"] = loss
        if reward is not None:
            metrics["reward"] = reward
        if success_rate is not None:
            metrics["success_rate"] = success_rate

        return new_params, num_samples, metrics

    def evaluate(
        self, parameters: List[np.ndarray], config: Dict[str, str]
    ) -> Tuple[float, int, Dict]:
        """æœ¬åœ°è¯„ä¼°ï¼ˆä¿æŒ Flower åè®®ï¼šç¬¬ä¸€ä¸ªè¿”å›å€¼éœ€è¦æ˜¯ floatï¼‰"""
        self.set_parameters(parameters)

        logger.info(f"ğŸ“Š å¼€å§‹æœ¬åœ°è¯„ä¼° - æ¸¯å£: {self.port}")
        eval_metrics = self.client.evaluate() or {}

        # Flower evaluate å¿…é¡»è¿”å› (loss: float, num_examples: int, metrics: Dict)
        loss = _safe_float(eval_metrics.get("loss"), 0.0)  # æ²¡æœ‰å°±ç»™ 0.0
        reward = _safe_float(
            eval_metrics.get("avg_reward", eval_metrics.get("reward")), None
        )
        success_rate = _safe_float(
            eval_metrics.get("success_rate", eval_metrics.get("accuracy")), None
        )
        num_samples = int(eval_metrics.get("num_samples", 800))

        metrics = {"port": self.port, "num_samples": num_samples}
        if reward is not None:
            metrics["avg_reward"] = reward
        if success_rate is not None:
            metrics["success_rate"] = success_rate

        return float(loss), num_samples, metrics


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Flower è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯ï¼ˆå®¹é”™ç‰ˆï¼‰")
    parser.add_argument("--port", type=str, required=True, help="æ¸¯å£åç§°")
    parser.add_argument("--server", type=str, default="localhost:8080", help="æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--init", type=str, help="åˆå§‹æƒé‡æ–‡ä»¶è·¯å¾„")

    # è®­ç»ƒå‚æ•°
    parser.add_argument("--episodes", type=int, default=8, help="è®­ç»ƒ episodes æ•°")
    parser.add_argument("--ppo-epochs", type=int, default=4, help="PPO è½®æ•°")
    parser.add_argument("--batch-size", type=int, default=64, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--entropy-coef", type=float, default=0.01, help="ç†µç³»æ•°")

    args = parser.parse_args()

    logger.info(f"ğŸš€ å¯åŠ¨Flowerå®¢æˆ·ç«¯ - æ¸¯å£: {args.port}")
    logger.info(f"ğŸŒ æœåŠ¡å™¨åœ°å€: {args.server}")
    logger.info(
        f"âš™ï¸ è®­ç»ƒå‚æ•°: episodes={args.episodes}, ppo_epochs={args.ppo_epochs}, "
        f"batch_size={args.batch_size}, entropy_coef={args.entropy_coef}"
    )

    client = FlowerClient(
        port=args.port,
        server_address=args.server,
        init_weights=args.init,
        episodes=args.episodes,
        ppo_epochs=args.ppo_epochs,
        batch_size=args.batch_size,
        entropy_coef=args.entropy_coef,
    )

    # å®˜æ–¹æ¨èå¯åŠ¨æ–¹å¼ï¼ˆä¸å†ç”¨ start_numpy_clientï¼‰
    fl.client.start_client(server_address=args.server, client=client.to_client())


if __name__ == "__main__":
    main()
