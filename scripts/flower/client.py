#!/usr/bin/env python3
"""
Flowerè”é‚¦å­¦ä¹ å®¢æˆ·ç«¯
æ”¯æŒæŒ‡å®šæ¸¯å£ï¼Œä¸æœåŠ¡å™¨é€šä¿¡ï¼ŒçœŸæ­£è®­ç»ƒ
"""

import flwr as fl
import torch
import logging
import argparse
import os
import sys
import numpy as np
from typing import Dict, List, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.federated.fedavg_client import FedAvgClient

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FlowerClient(fl.client.NumPyClient):
    """Flowerå®¢æˆ·ç«¯å®ç°"""
    
    def __init__(self, port: str, server_address: str = "localhost:8080", init_weights: str = None, 
                 episodes: int = 8, ppo_epochs: int = 4, batch_size: int = 64, entropy_coef: float = 0.01):
        self.port = port
        self.server_address = server_address
        self.init_weights = init_weights
        self.episodes = episodes
        self.ppo_epochs = ppo_epochs
        self.batch_size = batch_size
        self.entropy_coef = entropy_coef
        self.client = FedAvgClient(port=port, init_weights=init_weights)
        
        # è·å–æ¨¡å‹å‚æ•°é”®çš„é¡ºåºï¼ˆå›ºå®šé¡ºåºé¿å…é”®é”™ä½ï¼‰
        self.param_keys = list(self.client.get_parameters().keys())
        logger.info(f"ğŸ”‘ å‚æ•°é”®é¡ºåº: {self.param_keys}")
        logger.info(f"âš™ï¸ è®­ç»ƒå‚æ•°: episodes={episodes}, ppo_epochs={ppo_epochs}, batch_size={batch_size}, entropy_coef={entropy_coef}")
        
    def get_parameters(self, config: Dict[str, str]) -> List[np.ndarray]:
        """è·å–æ¨¡å‹å‚æ•°"""
        params = self.client.get_parameters()
        # æŒ‰å›ºå®šé¡ºåºè¿”å›å‚æ•°
        return [params[key] for key in self.param_keys]
    
    def set_parameters(self, parameters: List[np.ndarray]) -> None:
        """è®¾ç½®æ¨¡å‹å‚æ•°"""
        params_dict = {key: param for key, param in zip(self.param_keys, parameters)}
        self.client.set_parameters(params_dict)
    
    def fit(self, parameters: List[np.ndarray], config: Dict[str, str]) -> Tuple[List[np.ndarray], int, Dict]:
        """è®­ç»ƒæ¨¡å‹"""
        # è®¾ç½®å‚æ•°
        self.set_parameters(parameters)
        
        # æœ¬åœ°è®­ç»ƒ - ä½¿ç”¨ä¼ å…¥çš„è®­ç»ƒå‚æ•°
        logger.info(f"ğŸ‹ï¸ å¼€å§‹æœ¬åœ°è®­ç»ƒ - æ¸¯å£: {self.port}")
        logger.info(f"ğŸ“Š è®­ç»ƒé…ç½®: episodes={self.episodes}, ppo_epochs={self.ppo_epochs}, batch_size={self.batch_size}")
        
        # è°ƒç”¨å®¢æˆ·ç«¯çš„è®­ç»ƒæ–¹æ³•ï¼Œä¼ å…¥è®­ç»ƒå‚æ•°
        train_stats = self.client.train(
            episodes=self.episodes,
            ppo_epochs=self.ppo_epochs,
            batch_size=self.batch_size,
            entropy_coef=self.entropy_coef
        )
        
        # è·å–è®­ç»ƒåçš„å‚æ•°
        new_params = self.get_parameters(config)
        
        # è¿”å›å‚æ•°ã€æ ·æœ¬æ•°ã€æŒ‡æ ‡ï¼ˆåŒ…å«è®­ç»ƒç»Ÿè®¡ä¿¡æ¯ï¼‰
        metrics = {
            "port": self.port,
            "episodes": self.episodes,
            "ppo_epochs": self.ppo_epochs,
            "batch_size": self.batch_size,
            "entropy_coef": self.entropy_coef,
            "loss": train_stats.get("loss", 0.0),
            "reward": train_stats.get("avg_reward", 0.0),
            "num_samples": train_stats.get("num_samples", 800)
        }
        
        return new_params, metrics["num_samples"], metrics
    
    def evaluate(self, parameters: List[np.ndarray], config: Dict[str, str]) -> Tuple[float, int, Dict]:
        """è¯„ä¼°æ¨¡å‹"""
        # è®¾ç½®å‚æ•°
        self.set_parameters(parameters)
        
        # æœ¬åœ°è¯„ä¼°
        logger.info(f"ğŸ“Š å¼€å§‹æœ¬åœ°è¯„ä¼° - æ¸¯å£: {self.port}")
        eval_metrics = self.client.evaluate()
        
        # è¿”å›æŸå¤±ã€æ ·æœ¬æ•°ã€æŒ‡æ ‡
        loss = eval_metrics.get("loss", 0.0)
        reward = eval_metrics.get("avg_reward", 0.0)
        num_samples = eval_metrics.get("num_samples", 800)
        
        metrics = {
            "port": self.port,
            "loss": loss,
            "reward": reward,
            "num_samples": num_samples
        }
        
        return loss, num_samples, metrics

def main():
    """å¯åŠ¨Flowerå®¢æˆ·ç«¯"""
    parser = argparse.ArgumentParser(description="Flowerè”é‚¦å­¦ä¹ å®¢æˆ·ç«¯")
    parser.add_argument("--port", type=str, required=True, help="æ¸¯å£åç§°")
    parser.add_argument("--server", type=str, default="localhost:8080", help="æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--init", type=str, help="åˆå§‹æƒé‡æ–‡ä»¶è·¯å¾„")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--episodes", type=int, default=8, help="è®­ç»ƒepisodesæ•°")
    parser.add_argument("--ppo-epochs", type=int, default=4, help="PPOè®­ç»ƒè½®æ•°")
    parser.add_argument("--batch-size", type=int, default=64, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--entropy-coef", type=float, default=0.01, help="ç†µç³»æ•°")
    
    args = parser.parse_args()
    
    logger.info(f"ğŸš€ å¯åŠ¨Flowerå®¢æˆ·ç«¯ - æ¸¯å£: {args.port}")
    logger.info(f"ğŸŒ æœåŠ¡å™¨åœ°å€: {args.server}")
    logger.info(f"âš™ï¸ è®­ç»ƒå‚æ•°: episodes={args.episodes}, ppo_epochs={args.ppo_epochs}, batch_size={args.batch_size}, entropy_coef={args.entropy_coef}")
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = FlowerClient(
        port=args.port, 
        server_address=args.server, 
        init_weights=args.init,
        episodes=args.episodes,
        ppo_epochs=args.ppo_epochs,
        batch_size=args.batch_size,
        entropy_coef=args.entropy_coef
    )
    
    # å¯åŠ¨å®¢æˆ·ç«¯
    fl.client.start_numpy_client(
        server_address=args.server,
        client=client,
    )

if __name__ == "__main__":
    main() 